{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2213f20d-2e49-4669-9c1d-96fa4253982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "CFG = {\n",
    "    \"extr_num\": 1,\n",
    "    \"top_k_extra\": 200,\n",
    "    \"data_dir\": \"data\",\n",
    "}\n",
    "CFG[\"out_dir\"] = f\"modified_data/{CFG['extr_num']}\"\n",
    "\n",
    "id_col = \"customer_id\"\n",
    "\n",
    "train_main_path  = os.path.join(CFG[\"data_dir\"], \"train_main_features.parquet\")\n",
    "test_main_path   = os.path.join(CFG[\"data_dir\"], \"test_main_features.parquet\")\n",
    "train_extra_path = os.path.join(CFG[\"data_dir\"], \"train_extra_features.parquet\")\n",
    "test_extra_path  = os.path.join(CFG[\"data_dir\"], \"test_extra_features.parquet\")\n",
    "target_path      = \"data/train_target.parquet\"\n",
    "\n",
    "\n",
    "train_main  = pl.read_parquet(train_main_path)\n",
    "test_main   = pl.read_parquet(test_main_path)\n",
    "train_extra = pl.read_parquet(train_extra_path)\n",
    "test_extra  = pl.read_parquet(test_extra_path)\n",
    "target      = pl.read_parquet(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5192cf56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440\n",
      "199\n",
      "2241\n"
     ]
    }
   ],
   "source": [
    "train_big = train_main.join(train_extra, on=id_col, how=\"left\").join(target, on=id_col, how=\"left\")\n",
    "test_big  = test_main.join(test_extra, on=id_col, how=\"left\")\n",
    "\n",
    "target_columns = [c for c in target.columns if c != id_col]\n",
    "\n",
    "feature_cols_all = [c for c in train_big.columns if c != id_col and c not in target_columns]\n",
    "main_feature_cols = [c for c in train_main.columns if c != id_col]\n",
    "extra_feature_cols = [c for c in train_extra.columns if c != id_col]\n",
    "\n",
    "print(len(feature_cols_all))\n",
    "print(len(main_feature_cols))\n",
    "print(len(extra_feature_cols))\n",
    "\n",
    "# Мне не нравится заполнение нулями\n",
    "# Требуется EDA\n",
    "# X_df = train_big.select(feature_cols_all).fill_null(0).to_pandas()\n",
    "# y_df = train_big.select(target_columns).to_pandas()\n",
    "\n",
    "X_df = train_big\n",
    "y_df = train_big.select(target_columns).to_pandas()\n",
    "\n",
    "# Вообще не знаю, нужна ли это строчка, нужен eda\n",
    "# На всякий случай: если где-то bool -> int\n",
    "# y_df = y_df.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15e8ec-bb63-465d-b3ab-03d2bb2a1bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 200\n",
      "building tree 2 of 200\n",
      "building tree 3 of 200\n",
      "building tree 4 of 200\n",
      "building tree 5 of 200\n",
      "building tree 6 of 200\n",
      "building tree 7 of 200\n",
      "building tree 8 of 200\n",
      "building tree 9 of 200\n",
      "building tree 10 of 200\n",
      "building tree 11 of 200\n",
      "building tree 12 of 200\n",
      "building tree 13 of 200\n",
      "building tree 14 of 200\n",
      "building tree 15 of 200\n",
      "building tree 16 of 200\n",
      "building tree 17 of 200\n",
      "building tree 18 of 200\n",
      "building tree 19 of 200\n",
      "building tree 20 of 200\n",
      "building tree 21 of 200\n",
      "building tree 22 of 200\n",
      "building tree 23 of 200\n",
      "building tree 24 of 200\n",
      "building tree 25 of 200\n",
      "building tree 26 of 200\n",
      "building tree 27 of 200\n",
      "building tree 28 of 200\n",
      "building tree 29 of 200\n",
      "building tree 30 of 200\n",
      "building tree 31 of 200\n",
      "building tree 32 of 200\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_df, y_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = ExtraTreesClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96916972-ce80-4026-aa19-cd908c2f65db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m scorer = make_scorer(f1_score, average=\u001b[33m\"\u001b[39m\u001b[33mmicro\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# n_repeats можно поднять до 10-20, но будет дольше\u001b[39;00m\n\u001b[32m      9\u001b[39m perm = permutation_importance(\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[43mmodel\u001b[49m,\n\u001b[32m     11\u001b[39m     X_val,\n\u001b[32m     12\u001b[39m     y_val,\n\u001b[32m     13\u001b[39m     scoring=scorer,\n\u001b[32m     14\u001b[39m     n_repeats=\u001b[32m5\u001b[39m,\n\u001b[32m     15\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     16\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m importances = pd.DataFrame({\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m\"\u001b[39m: feature_cols_all,\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimportance_mean\u001b[39m\u001b[33m\"\u001b[39m: perm.importances_mean,\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mimportance_std\u001b[39m\u001b[33m\"\u001b[39m: perm.importances_std\n\u001b[32m     23\u001b[39m }).sort_values(\u001b[33m\"\u001b[39m\u001b[33mimportance_mean\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     25\u001b[39m importance_pl = pl.from_pandas(importances)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# Permutation Importance (multilabel через f1_micro)\n",
    "# -----------------------------\n",
    "scorer = make_scorer(f1_score, average=\"micro\")\n",
    "\n",
    "# n_repeats можно поднять до 10-20, но будет дольше\n",
    "perm = permutation_importance(\n",
    "    model,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    scoring=scorer,\n",
    "    n_repeats=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    \"feature\": feature_cols_all,\n",
    "    \"importance_mean\": perm.importances_mean,\n",
    "    \"importance_std\": perm.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "importance_pl = pl.from_pandas(importances)\n",
    "\n",
    "# -----------------------------\n",
    "# Select top K only from extra\n",
    "# -----------------------------\n",
    "K = CFG[\"top_k_extra\"]\n",
    "\n",
    "extra_importance_pl = (\n",
    "    importance_pl\n",
    "    .filter(pl.col(\"feature\").is_in(extra_feature_cols))\n",
    "    .sort(\"importance_mean\", descending=True)\n",
    ")\n",
    "\n",
    "selected_extra_features = extra_importance_pl.head(K)[\"feature\"].to_list()\n",
    "\n",
    "final_feature_cols = main_feature_cols + selected_extra_features\n",
    "\n",
    "# -----------------------------\n",
    "# Final datasets\n",
    "# -----------------------------\n",
    "train_final = train_big.select([id_col] + target_columns + final_feature_cols)\n",
    "test_final  = test_big.select([id_col] + final_feature_cols)\n",
    "\n",
    "# -----------------------------\n",
    "# Save\n",
    "# -----------------------------\n",
    "os.makedirs(CFG[\"out_dir\"], exist_ok=True)\n",
    "\n",
    "train_out_path = os.path.join(CFG[\"out_dir\"], f\"train_extr{CFG['extr_num']}.parquet\")\n",
    "test_out_path  = os.path.join(CFG[\"out_dir\"], f\"test_extr{CFG['extr_num']}.parquet\")\n",
    "imp_out_path   = os.path.join(CFG[\"out_dir\"], f\"perm_importances_extr{CFG['extr_num']}.parquet\")\n",
    "sel_out_path   = os.path.join(CFG[\"out_dir\"], f\"selected_extra_features_top{K}_extr{CFG['extr_num']}.txt\")\n",
    "\n",
    "train_final.write_parquet(train_out_path)\n",
    "test_final.write_parquet(test_out_path)\n",
    "importance_pl.write_parquet(imp_out_path)\n",
    "\n",
    "with open(sel_out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for col in selected_extra_features:\n",
    "        f.write(col + \"\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save model\n",
    "# -----------------------------\n",
    "models_dir = \"models_extraction\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(models_dir, f\"extra_tree_model_extr{CFG['extr_num']}.joblib\")\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Также сохраняем информацию о фичах для будущего использования\n",
    "feature_info = {\n",
    "    \"main_features\": main_feature_cols,\n",
    "    \"selected_extra_features\": selected_extra_features,\n",
    "    \"final_features\": final_feature_cols,\n",
    "    \"target_columns\": target_columns,\n",
    "    \"feature_cols_all\": feature_cols_all,\n",
    "    \"id_col\": id_col,\n",
    "    \"extr_num\": CFG[\"extr_num\"],\n",
    "    \"top_k_extra\": K\n",
    "}\n",
    "\n",
    "feature_info_path = os.path.join(models_dir, f\"feature_info_extr{CFG['extr_num']}.joblib\")\n",
    "joblib.dump(feature_info, feature_info_path)\n",
    "\n",
    "print(\"------ DONE (multilabel) ------\")\n",
    "print(\"K extra selected:\", len(selected_extra_features))\n",
    "print(\"train_final shape:\", train_final.shape)\n",
    "print(\"test_final shape :\", test_final.shape)\n",
    "print(\"Saved:\")\n",
    "print(\" -\", train_out_path)\n",
    "print(\" -\", test_out_path)\n",
    "print(\" -\", imp_out_path)\n",
    "print(\" -\", sel_out_path)\n",
    "print(\" -\", model_path)\n",
    "print(\" -\", feature_info_path)\n",
    "\n",
    "# print(\"\\nTop-10 extra feature importances (perm, f1_micro):\")\n",
    "# print(extra_importance_pl.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd362635-0f7b-440a-835e-931dbb5403e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
